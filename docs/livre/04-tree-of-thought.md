# ğŸŒ³ Chapitre 4 : Tree-of-Thought (ToT)

---

## ğŸ¬ ScÃ¨ne d'ouverture : L'Impasse du Raisonnement LinÃ©aire

*Lina fixait son Ã©cran depuis une heure. Le test Ã©chouait de maniÃ¨re intermittente â€” parfois il passait, parfois non. Son chatbot avait dÃ©jÃ  proposÃ© trois solutions... qui n'avaient rien rÃ©solu.*

â€” "C'est comme si tu tirais au hasard," soupira-t-elle en fermant la quatriÃ¨me suggestion inutile.

Elle se leva et alla au tableau blanc. Comment rÃ©soudrait-elle ce problÃ¨me elle-mÃªme ?

Elle commenÃ§a Ã  Ã©crire :
- **HypothÃ¨se 1** : Race condition ?
- **HypothÃ¨se 2** : Ã‰tat partagÃ© corrompu ?
- **HypothÃ¨se 3** : Timing du mock ?
- **HypothÃ¨se 4** : Fuite de mÃ©moire entre tests ?

Puis elle nota des scores Ã  cÃ´tÃ© de chaque hypothÃ¨se :
- Race condition : **80%** (comportement alÃ©atoire classique)
- Ã‰tat partagÃ© : **60%** (possible mais les tests sont isolÃ©s)
- Timing mock : **40%** (peu probable, les mocks sont synchrones)
- Fuite mÃ©moire : **20%** (les tests sont courts)

Elle commenÃ§a Ã  explorer la piste de la race condition, gÃ©nÃ©ra des sous-hypothÃ¨ses, en Ã©valua certaines, en abandonna d'autres...

â€” "C'est Ã§a," rÃ©alisa-t-elle soudain. "Je ne pense pas en ligne droite. Je pense en **arbre**. J'explore plusieurs chemins, j'Ã©value lesquels sont prometteurs, et j'abandonne les impasses."

Elle retourna Ã  son code.

â€” "Et si je t'apprenais Ã  faire pareil ?"

---

## ğŸ¯ 4.1 Le ProblÃ¨me du Raisonnement LinÃ©aire

### 4.1.1 ğŸ”— La Limite Fondamentale

Les LLMs gÃ©nÃ¨rent du texte **token par token**, chaque token dÃ©pendant des prÃ©cÃ©dents. C'est la gÃ©nÃ©ration autorÃ©gressive.

![GÃ©nÃ©ration AutorÃ©gressive](images/autoregressive_gen.svg)

Si le modÃ¨le s'engage sur une mauvaise piste au token 50, il doit continuer sur cette piste jusqu'Ã  la fin. **Pas de retour en arriÃ¨re possible.**

### 4.1.2 ğŸ® Exemple Concret : Le Game of 24

Le **Game of 24** est un benchmark classique : utiliser quatre nombres avec +, -, Ã—, Ã· pour obtenir 24.

![Tree-of-Thought vs Linear](images/tot_vs_cot.svg)

### 4.1.3 ğŸ§  Pourquoi Ã‡a Marche

ToT imite le raisonnement humain naturel :

| ğŸ§  Ce que fait l'humain | ğŸŒ³ Ce que fait ToT |
|:------------------------|:-------------------|
| "Et si j'essayais X ?" | GÃ©nÃ©rer N pensÃ©es candidates |
| "Cette piste a l'air prometteuse" | Scorer chaque pensÃ©e (0-1) |
| "Je continue sur celle-ci" | SÃ©lectionner les meilleures |
| "Non, mauvaise idÃ©e, revenons" | Ã‰laguer et backtracker |

> ğŸ’¡ **Insight clÃ©** : Les humains ne pensent pas en ligne droite. Ils explorent, Ã©valuent, abandonnent, recommencent. ToT donne cette capacitÃ© aux LLMs.

---

## ğŸ“ 4.2 L'Algorithme Tree-of-Thought

### 4.2.1 ğŸ—ï¸ Structure de DonnÃ©es

Chaque pensÃ©e est un **nÅ“ud** dans un arbre :

```typescript
interface ThoughtNode {
  id: string;
  content: string;           // Le contenu de cette pensÃ©e
  score: number;             // Ã‰valuation de la promesse (0-1)
  depth: number;             // Profondeur dans l'arbre
  parent: ThoughtNode | null;
  children: ThoughtNode[];
  state: 'pending' | 'expanded' | 'pruned' | 'solution';
  metadata: {
    generatedAt: Date;
    evaluatedBy: 'self' | 'vote' | 'execution';
    confidence: number;
  };
}

interface ThoughtTree {
  root: ThoughtNode;
  problem: string;
  maxDepth: number;
  branchingFactor: number;   // Combien d'enfants par nÅ“ud
  solutions: ThoughtNode[];  // Solutions trouvÃ©es
}
```

### 4.2.2 ğŸ”„ Les Quatre Phases

![Phases ToT](images/tot_phases.svg)

1.  **DÃ©composer** : Casser le problÃ¨me en Ã©tapes.
2.  **GÃ©nÃ©rer** : CrÃ©er plusieurs options pour la prochaine Ã©tape.
3.  **Ã‰valuer** : Juger chaque option.
4.  **SÃ©lectionner** : Garder les meilleures et recommencer.

### 4.2.3 ğŸŒ² Visualisation d'un Arbre

![Tree-of-Thought Example](images/tot_example_tree.svg)

---

## ğŸ§­ 4.3 Les StratÃ©gies de Recherche

Il existe plusieurs faÃ§ons de parcourir l'arbre. Le choix de la stratÃ©gie impacte fortement les rÃ©sultats.

### 4.3.1 ğŸ“Š Comparaison des StratÃ©gies

| ğŸ§­ StratÃ©gie | ğŸ“ Description | âœ… Avantages | âš ï¸ InconvÃ©nients |
|:-------------|:---------------|:-------------|:-----------------|
| **BFS** | Explorer tous les nÅ“uds d'un niveau avant le suivant | Ne rate pas de solution proche | CoÃ»teux en mÃ©moire et appels |
| **DFS** | Explorer une branche jusqu'au bout | Ã‰conome en mÃ©moire | Peut s'enliser dans une impasse |
| **Beam** | Garder les K meilleurs Ã  chaque niveau | Bon compromis | Peut Ã©laguer une bonne branche |

### 4.3.2 ğŸ“ Visualisation des StratÃ©gies

![StratÃ©gies de Recherche](images/search_strategies.svg)

### 4.3.5 ğŸ¯ Configuration RecommandÃ©e par TÃ¢che

| ğŸ¯ Type de TÃ¢che | ğŸ§­ StratÃ©gie | ğŸŒ¿ Branching | ğŸ“ Depth | ğŸ“Š Beam |
|:-----------------|:-------------|:------------:|:--------:|:-------:|
| Bug simple | BFS | 3 | 2 | 3 |
| Bug complexe | Beam | 4 | 4 | 3 |
| Refactoring | DFS | 2 | 6 | 2 |
| Architecture | Beam | 5 | 3 | 4 |
| Optimisation | Beam | 4 | 5 | 3 |

---

## âš–ï¸ 4.4 L'Ã‰valuation des PensÃ©es

L'Ã©valuation est **critique** â€” une mauvaise Ã©valuation mÃ¨ne Ã  de mauvaises dÃ©cisions d'Ã©lagage.

### 4.4.1 ğŸ“Š Trois MÃ©thodes d'Ã‰valuation

| ğŸ”§ MÃ©thode | ğŸ“ Description | âœ… Avantages | âš ï¸ InconvÃ©nients |
|:-----------|:---------------|:-------------|:-----------------|
| **Self** | Le LLM Ã©value ses propres pensÃ©es | Simple, un seul appel | Biais vers ses propres idÃ©es |
| **Vote** | Plusieurs Ã©valuations, puis moyenne | Plus robuste | Plus d'appels API |
| **Execution** | ExÃ©cuter le code et vÃ©rifier | Objectif, prÃ©cis | Seulement pour le code |

### ğŸ§ª Laboratoire : ImplÃ©menter une Auto-Ã©valuation

Voici comment implÃ©menter une Ã©valuation robuste avec un LLM :

```typescript
async function selfEvaluate(thought: ThoughtNode, problem: string): Promise<number> {
  const prompt = `
    ProblÃ¨me original : ${problem}

    PensÃ©e Ã  Ã©valuer : ${thought.content}

    Ã‰value cette pensÃ©e sur une Ã©chelle de 0 Ã  1 :
    - 0.0-0.2 : Hors sujet ou fausse
    - 0.3-0.4 : Peu prometteuse
    - 0.5-0.6 : Pertinente, mÃ©rite exploration
    - 0.7-0.8 : Prometteuse, probablement sur la bonne piste
    - 0.9-1.0 : Excellente, trÃ¨s probablement la solution

    RÃ©ponds UNIQUEMENT avec un nombre flottant (ex: 0.85).
  `;

  const response = await llm.complete(prompt);
  return parseFloat(response.trim());
}
```

---

## ğŸ’» 4.5 ImplÃ©mentation Grok-CLI

### 4.5.1 ğŸ“ Architecture du Module

```
src/agent/reasoning/
â”œâ”€â”€ index.ts                 # Point d'entrÃ©e, export
â”œâ”€â”€ tree-of-thought.ts       # ğŸŒ³ ImplÃ©mentation principale
â”œâ”€â”€ thought-generator.ts     # ğŸŒ± GÃ©nÃ©ration de pensÃ©es
â”œâ”€â”€ thought-evaluator.ts     # âš–ï¸ Ã‰valuation
â”œâ”€â”€ search-strategies.ts     # ğŸ§­ BFS, DFS, Beam
â”œâ”€â”€ types.ts                 # ğŸ“ Types TypeScript
â””â”€â”€ prompts/
    â”œâ”€â”€ decompose.ts         # Prompts de dÃ©composition
    â”œâ”€â”€ generate.ts          # Prompts de gÃ©nÃ©ration
    â””â”€â”€ evaluate.ts          # Prompts d'Ã©valuation
```

---

## ğŸ¬ 4.6 Cas Pratiques

### 4.6.1 ğŸ› Cas 1 : Debugging d'une Fonction

**ProblÃ¨me** : "calculateDiscount retourne parfois NaN"

L'arbre gÃ©nÃ©rÃ© (simplifiÃ©) :
1.  **HypothÃ¨se NaN** (Score 0.9)
    *   **Div par 0** (Score 0.85) -> **TrouvÃ© : `total / price`** -> **Fix : `if (price === 0)`**
    *   **Input undefined** (Score 0.7) -> Non reproduit

### 4.6.2 ğŸ—ï¸ Cas 2 : Refactoring d'Architecture

**ProblÃ¨me** : "Refactorer UserService"

L'arbre gÃ©nÃ©rÃ© :
1.  **StratÃ©gie Domaine** (Score 0.9) -> **Auth/Profile/Settings** -> **Plan Migration**
2.  **StratÃ©gie Technique** (Score 0.6) -> Controller/Service -> Ã‰laguÃ©

---

## âš™ï¸ 4.7 Optimisations et Bonnes Pratiques

### 4.7.1 ğŸ“Š RÃ©duire les Appels API

Au lieu d'Ã©valuer chaque pensÃ©e individuellement, demandez au LLM d'Ã©valuer une liste en une seule fois.

```typescript
// âœ… Ã‰valuation batch : 1 appel pour N pensÃ©es
async function batchEvaluate(thoughts: ThoughtNode[], problem: string): Promise<void> {
  const prompt = `... Ã‰value ces ${thoughts.length} pensÃ©es ...`;
  // ...
}
```

### 4.7.2 ğŸƒ Early Stopping

Si vous trouvez un score > 0.95, arrÃªtez tout et retournez la solution ! Pas besoin d'Ãªtre perfectionniste si le code marche.

---

## âš ï¸ 4.8 Limitations : Quand Ne Pas Utiliser ToT

ToT est puissant mais coÃ»teux.

| Configuration | Appels max | CoÃ»t estimÃ© |
|:--------------|:----------:|:-----------:|
| Branching=3, Depth=4 | 3â´ = 81 | ~$0.40 |
| Branching=4, Depth=4 | 4â´ = 256 | ~$1.30 |

> âš ï¸ **RÃ¨gle** : N'utilisez ToT que pour les problÃ¨mes complexes (debugging difficile, architecture). Pour "Quelle heure est-il ?", un appel direct suffit.

---

## ğŸ“ 4.9 Points ClÃ©s Ã  Retenir

*   **ToT** permet de sortir des impasses du raisonnement linÃ©aire.
*   **Beam Search** est souvent la meilleure stratÃ©gie pour le code (Ã©quilibre coÃ»t/qualitÃ©).
*   **L'Ã©valuation** est l'Ã©tape la plus difficile et la plus importante.

---

| â¬…ï¸ PrÃ©cÃ©dent | ğŸ“– Sommaire | â¡ï¸ Suivant |
|:-------------|:-----------:|:-----------|
| [Anatomie d'un Agent](03-anatomie-agent.md) | [Index](README.md) | [Monte-Carlo Tree Search](05-mcts.md) |
