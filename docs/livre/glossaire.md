# üìö Glossaire

> D√©finitions des termes techniques utilis√©s dans ce livre

---

## A

### Agent
Programme autonome capable de percevoir son environnement, prendre des d√©cisions et ex√©cuter des actions pour atteindre des objectifs. Contrairement √† un simple chatbot, un agent peut utiliser des outils et persister entre les sessions.

### Attention (M√©canisme d')
Composant cl√© des Transformers permettant au mod√®le de "regarder" toutes les positions d'une s√©quence simultan√©ment et de pond√©rer leur importance relative. Voir : *Self-Attention*, *Multi-Head Attention*.

### Autor√©gressif
Mode de g√©n√©ration o√π chaque token est produit en fonction des tokens pr√©c√©dents. Les LLMs g√©n√®rent du texte token par token, sans possibilit√© de retour en arri√®re.

---

## B

### Backpropagation (MCTS)
Phase finale de MCTS o√π le r√©sultat d'une simulation est propag√© vers le haut de l'arbre pour mettre √† jour les statistiques de chaque n≈ìud travers√©.

### Beam Search
Strat√©gie de recherche qui maintient les K meilleures solutions √† chaque √©tape, offrant un compromis entre exploration exhaustive (BFS) et exploration profonde (DFS).

### BFS (Breadth-First Search)
Parcours en largeur d'abord. Explore tous les n≈ìuds d'un niveau avant de passer au suivant. Garantit de trouver la solution la plus proche mais co√ªteux en m√©moire.

### BPE (Byte Pair Encoding)
Algorithme de tokenization qui fusionne it√©rativement les paires de caract√®res les plus fr√©quentes. Utilis√© par GPT et la plupart des LLMs modernes.

---

## C

### Chain-of-Thought (CoT)
Technique de prompting o√π on demande au LLM de "penser √©tape par √©tape", am√©liorant ses performances sur les t√¢ches de raisonnement. Pr√©curseur de Tree-of-Thought.

### Chunk (Chunking)
Division d'un document en segments plus petits pour l'indexation RAG. Le chunking AST respecte la structure syntaxique du code (fonctions, classes).

### Compression de Contexte
Techniques pour r√©duire la taille du contexte envoy√© au LLM tout en pr√©servant l'information essentielle : r√©sum√©, masquage, d√©duplication s√©mantique.

### Cosine Similarity
Mesure de similarit√© entre deux vecteurs bas√©e sur l'angle entre eux. Valeur entre -1 et 1, o√π 1 = identique. Utilis√©e pour comparer des embeddings.

---

## D

### DFS (Depth-First Search)
Parcours en profondeur d'abord. Explore une branche jusqu'au bout avant de revenir. √âconome en m√©moire mais peut s'enliser dans des impasses.

### Dependency Graph
Graphe repr√©sentant les d√©pendances entre fichiers/modules d'un codebase. Utilis√© par Dependency-Aware RAG pour enrichir le contexte.

---

## E

### Early Stopping
Technique d'optimisation qui arr√™te la recherche d√®s qu'une solution satisfaisante est trouv√©e, √©vitant des calculs inutiles.

### Embedding
Repr√©sentation vectorielle dense d'un texte dans un espace √† haute dimension (768-1536 dimensions). Capture le sens s√©mantique.

### √âpisodique (M√©moire)
Type de m√©moire stockant les √©v√©nements pass√©s : conversations, actions, r√©sultats. R√©pond √† "Que s'est-il pass√© ?".

### Expansion (MCTS)
Phase de MCTS o√π un nouveau n≈ìud enfant est ajout√© √† un n≈ìud feuille s√©lectionn√©.

---

## F

### Few-Shot Learning
Apprentissage √† partir de quelques exemples fournis dans le prompt. Contraste avec Zero-Shot (aucun exemple).

### Fine-Tuning
Entra√Ænement suppl√©mentaire d'un mod√®le pr√©-entra√Æn√© sur des donn√©es sp√©cifiques pour l'adapter √† une t√¢che.

### FrugalGPT
Approche de Stanford (2023) pour r√©duire les co√ªts API en routant les requ√™tes vers le mod√®le le moins cher capable de les traiter.

---

## G

### G√©n√©ration Autor√©gressive
Voir *Autor√©gressif*.

### Guardrails
M√©canismes de s√©curit√© emp√™chant le LLM de produire du contenu dangereux ou d'ex√©cuter des actions interdites.

---

## H

### Hallucination
G√©n√©ration de contenu factuellement incorrect mais pr√©sent√© avec confiance par le LLM. Probl√®me majeur des mod√®les g√©n√©ratifs.

### Hook
Point d'extension permettant d'ex√©cuter du code personnalis√© avant/apr√®s certains √©v√©nements (PreToolUse, PostToolUse, etc.).

---

## I

### In-Context Learning
Capacit√© des LLMs √† apprendre de nouvelles t√¢ches √† partir d'exemples fournis dans le prompt, sans modification des poids.

### Iterative Repair
Approche de correction de bugs en boucle : g√©n√©rer un patch ‚Üí tester ‚Üí analyser l'erreur ‚Üí r√©g√©n√©rer. Inspir√©e de ChatRepair.

---

## L

### Lazy Loading
Technique de chargement diff√©r√© des modules lourds jusqu'√† leur premi√®re utilisation, r√©duisant le temps de d√©marrage.

### LLM (Large Language Model)
Mod√®le de langage de grande taille (milliards de param√®tres) entra√Æn√© sur des corpus massifs. Ex : GPT-4, Claude, Grok.

### LLMCompiler
Recherche de Berkeley (2023) sur l'ex√©cution parall√®le des outils avec analyse des d√©pendances.

---

## M

### MCP (Model Context Protocol)
Protocole standardis√© (Anthropic, 2024) pour connecter des LLMs √† des sources de donn√©es et outils externes via des serveurs.

### MCTS (Monte-Carlo Tree Search)
Algorithme de recherche combinant exploration stochastique et exploitation des r√©sultats. Utilis√© par AlphaGo.

### Multi-Head Attention
Extension de l'attention avec plusieurs "t√™tes" parall√®les, chacune capturant diff√©rents types de relations.

---

## O

### Observation Masking
Technique de compression filtrant les sorties d'outils non pertinentes pour la requ√™te courante.

### Orchestrateur
Composant central d'un agent coordonnant les autres modules : raisonnement, m√©moire, outils, s√©curit√©.

---

## P

### Proc√©durale (M√©moire)
Type de m√©moire stockant les s√©quences d'actions efficaces et workflows. R√©pond √† "Comment faire ?".

### Prompt Engineering
Art de formuler des instructions pour obtenir les meilleures r√©ponses d'un LLM.

### Prospective (M√©moire)
Type de m√©moire stockant les t√¢ches planifi√©es et rappels futurs. R√©pond √† "Que dois-je faire ?".

---

## R

### RAG (Retrieval-Augmented Generation)
Architecture combinant recherche documentaire et g√©n√©ration LLM. Le contexte pertinent est r√©cup√©r√© avant g√©n√©ration.

### ReAct
Pattern d'agent alternant Reasoning (raisonnement) et Acting (action) en boucle jusqu'√† r√©solution.

### Reranking
√âtape de RAG r√©ordonnant les r√©sultats de recherche par pertinence, souvent avec un cross-encoder.

### Rollout (MCTS)
Phase de simulation o√π une partie est jou√©e jusqu'au bout pour estimer la valeur d'un n≈ìud.

---

## S

### SBFL (Spectrum-Based Fault Localization)
Technique de localisation de bugs analysant quelles lignes sont ex√©cut√©es par les tests qui √©chouent vs r√©ussissent.

### S√©mantique (M√©moire)
Type de m√©moire stockant les connaissances factuelles : pr√©f√©rences, patterns, faits. R√©pond √† "Qu'ai-je appris ?".

### Self-Attention
M√©canisme o√π chaque position d'une s√©quence peut "regarder" toutes les autres positions pour calculer sa repr√©sentation.

### Streaming
Mode de g√©n√©ration o√π les tokens sont envoy√©s au client d√®s leur production, sans attendre la r√©ponse compl√®te.

---

## T

### Token
Unit√© de base manipul√©e par un LLM. Peut √™tre un mot, sous-mot, ou caract√®re selon le tokenizer. ~4 caract√®res en moyenne.

### Tokenization
Processus de d√©coupage du texte en tokens. Utilise g√©n√©ralement BPE ou SentencePiece.

### Tool-Use (Function Calling)
Capacit√© d'un LLM √† invoquer des fonctions/outils externes en g√©n√©rant des appels structur√©s (JSON).

### ToT (Tree-of-Thought)
Extension de Chain-of-Thought explorant plusieurs chemins de raisonnement en parall√®le et √©valuant les plus prometteurs.

### Transformer
Architecture de r√©seau de neurones introduite en 2017, bas√©e sur l'attention. Fondation de tous les LLMs modernes.

---

## U

### UCB1 (Upper Confidence Bound)
Formule utilis√©e par MCTS pour √©quilibrer exploration (n≈ìuds peu visit√©s) et exploitation (n≈ìuds prometteurs).

---

## V

### Vector Database
Base de donn√©es optimis√©e pour stocker et rechercher des embeddings par similarit√© (ex : FAISS, Pinecone, Chroma).

---

## Z

### Zero-Shot
Capacit√© d'un mod√®le √† effectuer une t√¢che sans exemple pr√©alable, uniquement √† partir d'instructions.

---

| üìñ Retour au sommaire |
|:---------------------:|
| [README](README.md) |
