# ğŸ² Chapitre 5 : Monte-Carlo Tree Search (MCTS)

---

## ğŸ¬ ScÃ¨ne d'ouverture : L'Algorithme d'AlphaGo

*Vendredi matin. Lina observait les logs de son agent ToT. Les rÃ©sultats Ã©taient meilleurs qu'avant, mais quelque chose la dÃ©rangeait.*

**Lina** *(pointant l'Ã©cran)* : "Regarde Ã§a. 87 branches explorÃ©es avant de trouver la solution. Quatre-vingt-sept."

**Marc** *(se penchant)* : "C'est beaucoup ?"

**Lina** : "La bonne piste Ã©tait la troisiÃ¨me. Les 84 autres ? Du gaspillage. Temps, tokens, argent â€” tout Ã§a pour explorer des impasses Ã©videntes."

*Elle fit dÃ©filer les logs.*

**Lina** : "LÃ , il explore 'vÃ©rifier si le fichier existe'. Le fichier existe, on le sait dÃ©jÃ , c'est dans le contexte. Mais l'agent ne fait pas le lien."

**Marc** : "Il explore Ã  l'aveugle."

**Lina** : "Exactement. C'est comme jouer aux Ã©checs en testant TOUS les coups possibles. Personne ne joue comme Ã§a."

*Elle se figea. Cette phrase venait de dÃ©clencher quelque chose.*

**Lina** *(lentement)* : "Personne... sauf les ordinateurs des annÃ©es 90. Avant DeepBlue. Avant..."

**Marc** : "AlphaGo ?"

*Lina ouvrit un onglet et tapa "AlphaGo MCTS paper".*

**Lina** : "AlphaGo n'explorait pas tous les coups possibles. Avec le Go, c'est impossible â€” il y a plus de positions que d'atomes dans l'univers."

**Marc** : "Comment il faisait alors ?"

**Lina** *(lisant rapidement)* : "Il **simulait** des parties complÃ¨tes. Ã€ partir de chaque coup possible, il jouait une partie fictive jusqu'Ã  la fin, comptait les victoires et les dÃ©faites, et apprenait quelles stratÃ©gies fonctionnaient vraiment."

*Elle se retourna vers Marc, les yeux brillants.*

**Lina** : "Tu vois la diffÃ©rence ? ToT Ã©value localement â€” 'cette pensÃ©e semble bonne'. MCTS Ã©value globalement â€” 'cette pensÃ©e MÃˆNE Ã  une solution'."

**Marc** : "C'est quoi MCTS exactement ?"

**Lina** : "Monte-Carlo Tree Search. L'algorithme qui a battu Lee Sedol en 2016. Qui a rÃ©volutionnÃ© l'IA de jeu."

*Elle ouvrit son IDE.*

**Lina** : "Et qui pourrait rÃ©volutionner notre agent."

---

## ğŸ¯ 5.1 Pourquoi MCTS pour les LLMs ?

### 5.1.1 âš ï¸ Le ProblÃ¨me de l'Ã‰valuation Locale

Tree-of-Thought Ã©value chaque pensÃ©e **localement** â€” est-ce que cette pensÃ©e semble bonne maintenant ? Mais une pensÃ©e qui semble bonne peut mener Ã  une impasse, et vice versa.

![Limite Ã‰valuation Locale gÃ©nÃ©rÃ© par Nanobanana](images/limit_eval_locale.svg)

### 5.1.2 ğŸ’¡ L'Intuition MCTS

Au lieu d'Ã©valuer localement, MCTS **simule jusqu'au bout** :

![MCTS : Simulation complÃ¨te](images/mcts-simulation.svg)

### 5.1.3 ğŸ”„ Les Quatre Phases de MCTS

![Cycle MCTS gÃ©nÃ©rÃ© par Nanobanana](images/mcts_cycle.svg)

| Phase | Action | Objectif |
|:------|:-------|:---------|
| **1ï¸âƒ£ SELECT** | Descendre avec UCB1 | Trouver le nÅ“ud le plus prometteur |
| **2ï¸âƒ£ EXPAND** | Ajouter un enfant | Explorer une nouvelle direction |
| **3ï¸âƒ£ SIMULATE** | Rollout complet | Estimer la qualitÃ© de ce chemin |
| **4ï¸âƒ£ BACKPROP** | Remonter le score | Mettre Ã  jour les statistiques |

---

## ğŸ“ 5.2 La Formule UCB1

### 5.2.1 âš–ï¸ Le Dilemme Exploration vs Exploitation

Tout algorithme de recherche doit Ã©quilibrer deux forces opposÃ©es :

| ğŸ¯ Exploitation | ğŸ” Exploration |
|:----------------|:---------------|
| Aller vers ce qu'on **sait** Ãªtre bon | Essayer des chemins **peu visitÃ©s** |
| Optimiser la solution actuelle | DÃ©couvrir de nouvelles possibilitÃ©s |
| Risque : rester coincÃ© dans un optimum local | Risque : perdre du temps sur des impasses |

MCTS balance les deux avec la formule **UCB1** (Upper Confidence Bound) :

![Formule UCB1](images/ucb1-formula.svg)

### 5.2.2 ğŸ§® Exemple de Calcul

![Calcul UCB1 en pratique](images/ucb1-calculation.svg)

### 5.2.3 ğŸ“ˆ Ã‰volution au Fil du Temps

| ğŸ“… Phase | ğŸ¯ Dominante | ğŸ“ Comportement |
|:---------|:-------------|:----------------|
| **DÃ©but** (peu de visites) | Exploration | Visite beaucoup de nÅ“uds, construit une image large |
| **Milieu** | Ã‰quilibre | Explore les prometteurs, abandonne les mauvais |
| **Fin** (beaucoup de visites) | Exploitation | Concentre sur les meilleurs, affine la solution |

---

## ğŸ¤– 5.3 Adaptation aux LLMs : RethinkMCTS

### 5.3.1 ğŸ”„ DiffÃ©rences avec MCTS Classique

| Aspect | ğŸ® MCTS Jeux | ğŸ¤– MCTS LLM |
|:-------|:-------------|:------------|
| **Actions** | DiscrÃ¨tes (coups de Go) | Continues (texte libre) |
| **Simulation** | Rapide (rÃ¨gles du jeu) | Lente (appel LLM) |
| **RÃ©compense** | Victoire/dÃ©faite binaire | QualitÃ© de la solution (0-1) |
| **Ã‰tat terminal** | Fin de partie | Solution trouvÃ©e ou profondeur max |
| **CoÃ»t par simulation** | ~0.001s | ~2-10s |

### 5.3.2 ğŸ² Le Rollout LLM

Au lieu de simuler une partie de Go, on demande au LLM de **simuler une rÃ©solution complÃ¨te** :

```typescript
async function llmRollout(node: MCTSNode, problem: string): Promise<number> {
  const path = getPath(node).map(n => `â†’ ${n.action}`).join('\n');

  const prompt = `
    ProblÃ¨me : ${problem}

    Chemin actuel :
    ${path}

    Continue cette approche jusqu'Ã  la rÃ©solution.
    Sois concis mais montre chaque Ã©tape.

    Ã€ la fin, Ã©value le succÃ¨s :
    - 0.0-0.2 : Ã‰chec total, mauvaise direction
    - 0.3-0.5 : Partiellement rÃ©solu
    - 0.6-0.8 : Presque rÃ©solu
    - 0.9-1.0 : ComplÃ¨tement rÃ©solu

    SCORE: [ton score ici]
  `;

  const response = await llm.complete(prompt, { temperature: 0.7 });

  // Extraire le score
  const match = response.match(/SCORE:\s*([\d.]+)/i);
  return match ? parseFloat(match[1]) : 0.5;
}
```

### 5.3.3 âš¡ Le Rollout avec ExÃ©cution RÃ©elle

Pour le code, on peut obtenir un feedback **objectif** en exÃ©cutant rÃ©ellement :

```typescript
async function executionRollout(node: MCTSNode, context: CodeContext): Promise<number> {
  // 1. GÃ©nÃ©rer le code complet basÃ© sur le chemin
  const code = await generateCode(node, context);

  try {
    // 2. ExÃ©cuter dans une sandbox
    await sandbox.execute(code);

    // 3. Lancer les tests
    const testResult = await runTests(context.testFile);

    // 4. Score basÃ© sur les tests passÃ©s
    if (testResult.allPassed) {
      return 1.0; // ğŸ¯ Solution parfaite !
    }

    return testResult.passed / testResult.total;
  } catch (error) {
    // Erreur = mauvaise solution
    return 0.1;
  }
}
```

### 5.3.4 ğŸ”€ Le Rollout Hybride (RecommandÃ©)

```typescript
async function hybridRollout(
  node: MCTSNode,
  problem: string,
  context?: CodeContext
): Promise<number> {
  // Ã‰tape 1 : Ã‰valuation rapide par LLM
  const llmScore = await llmRollout(node, problem);

  // Ã‰tape 2 : Si prometteur ET on a des tests, vÃ©rifier pour de vrai
  if (llmScore >= 0.7 && context?.hasTests) {
    return executionRollout(node, context);
  }

  return llmScore;
}
```

| ğŸ”§ MÃ©thode | âš¡ Vitesse | ğŸ¯ PrÃ©cision | ğŸ“‹ Cas d'usage |
|:-----------|:----------|:-------------|:---------------|
| LLM seul | Rapide (~3s) | Approximative | Exploration large |
| ExÃ©cution seule | Lente (~10s) | Objective | Validation finale |
| Hybride | Optimale | Meilleure des deux | Production |

---

## ğŸ’» 5.4 Algorithme Complet

### 5.4.1 ğŸ—ï¸ Structure de DonnÃ©es

```typescript
interface MCTSNode {
  id: string;
  action: string;           // L'action/pensÃ©e de ce nÅ“ud
  parent: MCTSNode | null;
  children: MCTSNode[];

  // ğŸ“Š Statistiques MCTS
  visits: number;           // N (nombre de visites)
  totalReward: number;      // Somme des rÃ©compenses
  meanReward: number;       // W/N (taux de succÃ¨s moyen)
  bestReward: number;       // Meilleure rÃ©compense vue

  // ğŸ·ï¸ MÃ©tadonnÃ©es
  depth: number;
  isTerminal: boolean;
  isFullyExpanded: boolean;
}

interface MCTSConfig {
  explorationConstant: number;  // C (default âˆš2 â‰ˆ 1.41)
  maxIterations: number;        // Budget de simulations
  maxDepth: number;             // Profondeur max de l'arbre
  rolloutMethod: 'llm' | 'execution' | 'hybrid';
  expansionWidth: number;       // Nombre d'enfants par expansion
  earlyStopThreshold: number;   // Score pour arrÃªter tÃ´t (default 0.95)
}
```

### 5.4.2 ğŸ’» ImplÃ©mentation RÃ©elle

Voici la vÃ©ritable implÃ©mentation de MCTS dans `Grok-CLI` (extraite de `src/agent/reasoning/mcts.ts`), incluant le mÃ©canisme de **Rethink** qui permet de raffiner les pensÃ©es erronÃ©es :

```typescript
// src/agent/reasoning/mcts.ts
export class MCTS {
  async search(problem: Problem): Promise<ReasoningResult> {
    // ... initialisation ...

    // CrÃ©er la racine
    this.root = this.createNode(`Understanding the problem: ${problem.description}`, "analysis", null, 0);

    // Boucle principale MCTS
    for (let i = 0; i < this.config.maxIterations; i++) {
      this.stats.iterations = i + 1;

      // 1ï¸âƒ£ SELECTION : Descente avec UCB1
      const selectedNode = this.select(this.root);

      // 2ï¸âƒ£ EXPANSION
      if (selectedNode.depth < this.config.maxDepth) {
        await this.expand(selectedNode, problem);
      }

      // 3ï¸âƒ£ SIMULATION & Ã‰VALUATION
      if (selectedNode.children.length > 0) {
        for (const child of selectedNode.children) {
          await this.simulate(child, problem);
        }
      }

      // 4ï¸âƒ£ BACKPROPAGATION
      this.backpropagate(selectedNode);

      // 5ï¸âƒ£ RETHINK (NouveautÃ© Grok-CLI)
      // Si une pensÃ©e a Ã©chouÃ© mais semble prometteuse, on la "repense"
      if (this.config.useRethink) {
        await this.rethink(selectedNode, problem);
      }

      // Early stopping si solution excellente trouvÃ©e
      const solution = this.findBestSolution();
      if (solution && solution.score > 0.9) break;
    }

    return this.buildResult();
  }

  // Calcul UCB1 (Upper Confidence Bound)
  private calculateUCB1(node: ThoughtNode, parentVisits: number): number {
    if (node.visits === 0) return Infinity; // Exploration infinie pour les non-visitÃ©s

    const exploitation = node.score / node.visits;
    const exploration = this.config.explorationConstant *
      Math.sqrt(Math.log(parentVisits) / node.visits);

    return exploitation + exploration;
  }

  // MÃ©canisme de Rethink
  private async rethink(node: ThoughtNode, _problem: Problem): Promise<void> {
    const nodesToRethink = this.findNodesNeedingRethink(node);

    for (const n of nodesToRethink) {
      if (n.metadata.feedback) {
        // Demander au LLM de corriger sa pensÃ©e
        const refinedContent = await this.refineThought(n, n.metadata.feedback);

        // CrÃ©er une version raffinÃ©e
        const refinedNode = this.createNode(refinedContent, n.type, n.parent, n.depth);
        refinedNode.state = "refined";

        if (n.parent) n.parent.children.push(refinedNode);
        n.state = "pruned"; // On Ã©lague l'ancienne version
      }
    }
  }
}
```

---

## ğŸ“ 5.5 ImplÃ©mentation Grok-CLI

### 5.5.1 ğŸ“‚ Architecture du Module

```
src/agent/reasoning/
â”œâ”€â”€ mcts.ts                  # ğŸ² ImplÃ©mentation principale
â”œâ”€â”€ mcts-node.ts             # ğŸŒ³ Classe MCTSNode
â”œâ”€â”€ rollout/
â”‚   â”œâ”€â”€ llm-rollout.ts       # ğŸ¤– Simulation par LLM
â”‚   â”œâ”€â”€ execution-rollout.ts # âš¡ Simulation par exÃ©cution
â”‚   â””â”€â”€ hybrid-rollout.ts    # ğŸ”€ Combinaison des deux
â”œâ”€â”€ selection/
â”‚   â”œâ”€â”€ ucb1.ts              # ğŸ“ Formule UCB1 standard
â”‚   â””â”€â”€ puct.ts              # ğŸ¯ Variante PUCT (style AlphaGo)
â””â”€â”€ config.ts                # âš™ï¸ Configuration
```

### 5.5.2 ğŸ¯ Variante PUCT (Style AlphaGo)

AlphaGo utilise PUCT au lieu d'UCB1, avec des **prior probabilities** :

```typescript
// src/agent/reasoning/selection/puct.ts
export class PUCTSelector {
  private cPuct: number;

  constructor(cPuct: number = 1.0) {
    this.cPuct = cPuct;
  }

  select(node: MCTSNode): MCTSNode {
    let bestScore = -Infinity;
    let bestChild: MCTSNode | null = null;

    const sqrtParentVisits = Math.sqrt(node.visits);

    for (const child of node.children) {
      // PUCT inclut une prior probability P(a)
      // Pour un LLM : score initial de l'Ã©valuation
      const prior = child.priorProbability ?? 1 / node.children.length;

      const exploitation = child.meanReward;
      const exploration = this.cPuct * prior * sqrtParentVisits / (1 + child.visits);

      const puct = exploitation + exploration;

      if (puct > bestScore) {
        bestScore = puct;
        bestChild = child;
      }
    }

    return bestChild!;
  }
}
```

| ğŸ”§ Formule | ğŸ“ UCB1 | ğŸ¯ PUCT |
|:-----------|:--------|:--------|
| Prior | Non | Oui (score LLM initial) |
| Origine | Bandits manchots | AlphaGo |
| Avantage | Simple | Utilise les connaissances du LLM |

---

## ğŸ”€ 5.6 Combinaison ToT + MCTS

### 5.6.1 ğŸ¯ Quand Utiliser Quoi ?

| Situation | Recommandation | Raison |
|:----------|:---------------|:-------|
| ProblÃ¨me avec solution connue | ğŸŒ³ ToT | Exploration large suffisante |
| ProblÃ¨me ouvert/crÃ©atif | ğŸ² MCTS | Besoin de simulation profonde |
| Budget API limitÃ© | ğŸŒ³ ToT | MCTS plus coÃ»teux |
| Code avec tests | ğŸ² MCTS | Feedback objectif par exÃ©cution |
| Architecture/design | ğŸ”€ Hybride | ToT gÃ©nÃ¨re, MCTS Ã©value |

### 5.6.2 ğŸ—ï¸ Architecture Hybride

```typescript
// src/agent/reasoning/hybrid-reasoner.ts
export class HybridReasoner {
  private tot: TreeOfThought;
  private mcts: MonteCarloTreeSearch;

  async solve(problem: string, context: CodeContext): Promise<Solution> {
    // ğŸ“‹ Phase 1 : ToT pour gÃ©nÃ©rer des candidats rapidement
    console.log('Phase 1: ToT exploration...');
    const candidates = await this.tot.solve(problem);

    // âš¡ Si ToT trouve une excellente solution, l'utiliser
    if (candidates[0]?.score >= 0.9) {
      console.log('âœ… ToT found excellent solution, skipping MCTS');
      return candidates[0];
    }

    // ğŸ² Phase 2 : MCTS pour affiner les meilleurs candidats
    console.log('Phase 2: MCTS refinement...');
    const topCandidates = candidates.slice(0, 3);

    const mctsSolutions = await Promise.all(
      topCandidates.map(candidate =>
        this.mcts.search(problem, {
          ...context,
          initialPath: candidate.path.join(' â†’ ')
        })
      )
    );

    // ğŸ† Retourner la meilleure solution MCTS
    return mctsSolutions.reduce((best, sol) =>
      sol.score > best.score ? sol : best
    );
  }
}
```

![Pipeline Hybride gÃ©nÃ©rÃ© par Nanobanana](images/hybrid_pipeline.svg)

---

## ğŸ¬ 5.7 Cas Pratiques

### 5.7.1 ğŸ› Cas 1 : Bug de Concurrence

![Cas pratique : Bug de concurrence](images/mcts-case-concurrency.svg)

### 5.7.2 ğŸ—„ï¸ Cas 2 : Optimisation SQL

![Cas pratique : Optimisation SQL](images/mcts-case-sql.svg)

### 5.7.3 ğŸ§® Cas 3 : GÃ©nÃ©ration d'Algorithme

![Cas pratique : GÃ©nÃ©ration d'algorithme](images/mcts-case-algorithm.svg)

---

## âš™ï¸ 5.8 Optimisations AvancÃ©es

### 5.8.1 ğŸ”€ ParallÃ©lisation des Rollouts

```typescript
async function parallelMCTS(problem: string, numWorkers: number = 4): Promise<Solution> {
  const root = createRoot(problem);

  // Diviser les itÃ©rations entre workers
  const iterationsPerWorker = Math.ceil(config.maxIterations / numWorkers);

  await Promise.all(
    Array(numWorkers).fill(null).map(async (_, workerId) => {
      for (let i = 0; i < iterationsPerWorker; i++) {
        const node = selectAndExpand(root);

        // Ajouter "virtual loss" pendant la simulation
        node.visits++;  // Ã‰vite que d'autres workers sÃ©lectionnent le mÃªme

        // Les rollouts peuvent Ãªtre parallÃ¨les
        const reward = await simulate(node);

        // Backprop avec le vrai reward
        backpropagate(node, reward);
      }
    })
  );

  return extractBestPath(root);
}
```

### 5.8.2 ğŸ“ Progressive Widening

Limiter le nombre d'enfants **progressivement** selon les visites :

```typescript
function shouldExpand(node: MCTSNode, alpha: number = 0.5): boolean {
  // Formule : max_children âˆ visits^alpha
  const maxChildren = Math.ceil(Math.pow(node.visits, alpha));
  return node.children.length < maxChildren;
}

// Avec alpha = 0.5 :
// - 1 visite   â†’ max 1 enfant
// - 4 visites  â†’ max 2 enfants
// - 9 visites  â†’ max 3 enfants
// - 16 visites â†’ max 4 enfants
```

### 5.8.3 ğŸ’¾ Table de Transposition

Ã‰viter de recalculer pour des **Ã©tats identiques** :

```typescript
const transpositionTable = new Map<string, MCTSNode>();

function getOrCreateNode(state: string, parent: MCTSNode): MCTSNode {
  const key = hashState(state);

  if (transpositionTable.has(key)) {
    const existing = transpositionTable.get(key)!;
    existing.addParent(parent);  // DAG au lieu d'arbre
    return existing;
  }

  const node = new MCTSNode(state, parent);
  transpositionTable.set(key, node);
  return node;
}
```

---

## ğŸ“Š 5.9 MÃ©triques et Debugging

### 5.9.1 ğŸ“ˆ MÃ©triques Importantes

| MÃ©trique | Description | Valeur typique |
|:---------|:------------|:---------------|
| `totalIterations` | Simulations effectuÃ©es | 50-200 |
| `nodesExpanded` | NÅ“uds crÃ©Ã©s | 100-500 |
| `maxDepthReached` | Profondeur max | 4-8 |
| `convergenceIteration` | Quand la solution s'est stabilisÃ©e | ~30-60% du budget |
| `explorationRatio` | % visites sur nÅ“uds peu visitÃ©s | 30-50% au dÃ©but |
| `averageRolloutTime` | Temps moyen par simulation | 2-10s |

### 5.9.2 ğŸŒ³ Visualisation de l'Arbre

```typescript
function visualizeTree(root: MCTSNode, maxDepth: number = 3): string {
  const lines: string[] = [];

  function traverse(node: MCTSNode, prefix: string, isLast: boolean): void {
    const connector = isLast ? 'â””â”€' : 'â”œâ”€';
    const stats = `[${node.visits}v, ${(node.meanReward * 100).toFixed(0)}%]`;
    const action = node.action.substring(0, 40);

    lines.push(`${prefix}${connector} ${action} ${stats}`);

    if (node.depth < maxDepth && node.children.length > 0) {
      const children = node.children.sort((a, b) => b.visits - a.visits);
      children.forEach((child, i) => {
        const extension = isLast ? '   ' : 'â”‚  ';
        traverse(child, prefix + extension, i === children.length - 1);
      });
    }
  }

  traverse(root, '', true);
  return lines.join('\n');
}
```

```
Exemple de sortie :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â””â”€ Debug le bug de connexion [50v, 85%]
   â”œâ”€ Bug cleanup [35v, 92%]
   â”‚  â”œâ”€ VÃ©rifier Ã©tat avant dÃ©crÃ©menter [28v, 95%]
   â”‚  â””â”€ Ajouter logging [7v, 70%]
   â””â”€ Race condition [12v, 40%]
      â””â”€ Ajouter mutex [5v, 50%]
```

---

## ğŸ“ 5.10 Points ClÃ©s Ã  Retenir

### ğŸ¯ Sur le ProblÃ¨me

| Concept | Point clÃ© |
|:--------|:----------|
| **Limite ToT** | L'Ã©valuation locale ne prÃ©dit pas le succÃ¨s final |
| **Solution MCTS** | Simuler jusqu'au bout avant de juger |
| **Inspiration** | AlphaGo a battu les humains avec MCTS |

### ğŸ“ Sur UCB1

| Concept | Point clÃ© |
|:--------|:----------|
| **Formule** | UCB1 = W/N + C Ã— âˆš(ln(P)/N) |
| **Balance** | Exploitation (W/N) + Exploration (âˆš...) |
| **Ã‰volution** | Exploration â†’ Ã‰quilibre â†’ Exploitation |

### ğŸ”„ Sur les 4 Phases

| Phase | Action | Objectif |
|:------|:-------|:---------|
| Select | Descendre avec UCB1 | Trouver le nÅ“ud prometteur |
| Expand | Ajouter un enfant | Explorer nouvelle direction |
| Simulate | Rollout complet | Estimer la qualitÃ© |
| Backprop | Remonter le score | Mettre Ã  jour les stats |

### ğŸ’» Sur l'ImplÃ©mentation

| Concept | Point clÃ© |
|:--------|:----------|
| **Fichier** | `src/agent/reasoning/mcts.ts` |
| **Rollout** | LLM (rapide) ou ExÃ©cution (prÃ©cis) ou Hybride |
| **Variante** | PUCT pour utiliser les priors du LLM |
| **Hybride** | ToT gÃ©nÃ¨re candidats â†’ MCTS affine |

---

## ğŸ‹ï¸ 5.11 Exercices

### Exercice 1 : Visualisation UCB1 (30 min)

ImplÃ©mentez une fonction qui affiche l'Ã©volution des scores UCB1 au fil des itÃ©rations pour un nÅ“ud donnÃ©.

### Exercice 2 : Benchmark ToT vs MCTS (1h)

Comparez ToT vs MCTS sur 5 bugs avec tests automatisÃ©s :
- Mesurez le taux de succÃ¨s
- Comptez le nombre d'itÃ©rations/appels API
- Mesurez le temps total

### Exercice 3 : PUCT avec Priors (45 min)

ImplÃ©mentez PUCT oÃ¹ les prior probabilities sont basÃ©es sur l'Ã©valuation LLM initiale de chaque action.

### Exercice 4 : ParallÃ©lisation (1h)

Ajoutez le support multi-thread avec virtual loss pour Ã©viter que plusieurs workers sÃ©lectionnent le mÃªme nÅ“ud.

---

## ğŸ“š 5.12 Pour Aller Plus Loin

### Publications

- Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." Nature
- Zhang, D., et al. (2024). "RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation." arXiv:2404.09932

### Code Source

- Grok-CLI : `src/agent/reasoning/mcts.ts`
- UCB1 : `src/agent/reasoning/selection/ucb1.ts`
- Rollouts : `src/agent/reasoning/rollout/`

---

## ğŸŒ… Ã‰pilogue : L'Algorithme des Champions

Lina exÃ©cuta son premier benchmark ToT vs MCTS.

```
Bug: Race condition sur compteur de connexions

ToT:  87 branches explorÃ©es, 4 solutions trouvÃ©es, 2 correctes
MCTS: 42 itÃ©rations, 1 solution trouvÃ©e, correcte

ToT time:  45s
MCTS time: 38s
```

Marc regarda les rÃ©sultats par-dessus son Ã©paule.

â€” "MCTS a trouvÃ© plus vite avec moins d'exploration ?"

â€” "Exactement. Au lieu de tout explorer Ã  l'aveugle, il simule chaque piste jusqu'au bout. Il **apprend** lesquelles fonctionnent vraiment."

â€” "Comme AlphaGo qui simule des parties entiÃ¨res avant de choisir un coup."

Lina hocha la tÃªte.

â€” "Et le meilleur ? On peut combiner les deux. ToT pour gÃ©nÃ©rer rapidement des candidats, MCTS pour les affiner. Le meilleur des deux mondes."

Elle sauvegarĞ´Ğ° son code.

â€” "Mais on n'a pas encore fini. MCTS trouve des solutions â€” mais que faire quand la solution ne marche pas du premier coup ? Il faut apprendre Ã  **rÃ©parer**."

â€” "ChatRepair ?"

â€” "ChatRepair. L'art de la rÃ©flexion et de l'auto-amÃ©lioration."

---

| â¬…ï¸ PrÃ©cÃ©dent | ğŸ“– Sommaire | â¡ï¸ Suivant |
|:-------------|:-----------:|:-----------|
| [Tree-of-Thought](04-tree-of-thought.md) | [Index](README.md) | [Repair et RÃ©flexion](06-repair-reflexion.md) |
