# ğŸŒ³ Chapitre 4 : Tree-of-Thought (ToT)

---

## ğŸ¬ ScÃ¨ne d'ouverture : L'Impasse du Raisonnement LinÃ©aire

*Mardi, 16h47. Lina fixait son Ã©cran depuis une heure. Le mÃªme test Ã©chouait de maniÃ¨re intermittente â€” parfois il passait, parfois non. Son agent avait dÃ©jÃ  proposÃ© trois solutions... qui n'avaient rien rÃ©solu.*

**Lina** *(fermant rageusement la quatriÃ¨me suggestion)* : "C'est comme si tu tirais au hasard !"

*Marc passa la tÃªte par la porte, attirÃ© par le bruit.*

**Marc** : "ProblÃ¨me ?"

**Lina** : "Le pire genre. Un test flaky. L'agent me propose des solutions, mais elles sont toutes... linÃ©aires. Il essaie une chose, Ã§a marche pas, il essaie autre chose. Comme un gamin qui appuie sur tous les boutons."

**Marc** *(entrant)* : "Montre-moi."

*Lina fit dÃ©filer l'historique des suggestions de l'agent. Chaque rÃ©ponse suivait le mÃªme pattern : une hypothÃ¨se, une solution, un Ã©chec, une nouvelle hypothÃ¨se sans lien avec la prÃ©cÃ©dente.*

**Marc** : "Il ne construit pas sur ses erreurs. Il recommence Ã  zÃ©ro Ã  chaque fois."

**Lina** : "Exactement !"

*Elle se leva et alla au tableau blanc.*

**Lina** : "Regarde comment MOI je rÃ©soudrais ce problÃ¨me."

*Elle commenÃ§a Ã  Ã©crire, parlant en mÃªme temps :*

**Lina** : "D'abord, je liste toutes les hypothÃ¨ses possibles."
- **HypothÃ¨se 1** : Race condition ?
- **HypothÃ¨se 2** : Ã‰tat partagÃ© corrompu ?
- **HypothÃ¨se 3** : Timing du mock ?
- **HypothÃ¨se 4** : Fuite de mÃ©moire entre tests ?

**Lina** : "Ensuite, je les Ã‰VALUE. Pas au hasard â€” avec mon expÃ©rience."

*Elle nota des scores Ã  cÃ´tÃ© de chaque hypothÃ¨se :*
- Race condition : **80%** *(comportement alÃ©atoire classique)*
- Ã‰tat partagÃ© : **60%** *(possible mais les tests sont isolÃ©s)*
- Timing mock : **40%** *(peu probable, les mocks sont synchrones)*
- Fuite mÃ©moire : **20%** *(les tests sont courts)*

**Marc** *(comprenant)* : "Tu explores en prioritÃ© les pistes les plus prometteuses."

**Lina** : "Et je DESCENDS dans chaque piste. Race condition â€” OK, oÃ¹ ? AccÃ¨s concurrent Ã  une variable ? Ã€ un fichier ? Ã€ une connexion DB ?"

*Elle dessina des branches partant de "Race condition".*

**Lina** : "Je gÃ©nÃ¨re des sous-hypothÃ¨ses. J'en Ã©value certaines. J'en abandonne d'autres quand elles mÃ¨nent nulle part."

*Elle recula pour voir l'ensemble. Un arbre Ã©tait apparu sur le tableau.*

**Marc** *(lentement)* : "Tu ne penses pas en ligne droite."

**Lina** *(les yeux brillants)* : "Je pense en **arbre**. J'explore plusieurs chemins en parallÃ¨le, j'Ã©value lesquels sont prometteurs, et j'abandonne les impasses. C'est Ã§a, le raisonnement humain."

*Elle se retourna vers son Ã©cran.*

**Lina** : "Et si j'apprenais Ã  mon agent Ã  faire pareil ?"

**Marc** : "Tree-of-Thought."

**Lina** : "Tu connais ?"

**Marc** *(souriant)* : "Shunyu Yao, Princeton, 2023. Le papier qui a changÃ© la faÃ§on dont on fait raisonner les LLMs."

*Lina attrapa son carnet.*

**Lina** : "Raconte."

---

## ğŸ“Š Tableau SynthÃ©tique â€” Chapitre 04

| Aspect | DÃ©tails |
|--------|---------|
| **Titre** | Tree-of-Thought â€” Raisonnement Arborescent |
| **Objectifs** | â€¢ Comprendre les limites du raisonnement linÃ©aire<br>â€¢ ImplÃ©menter ToT avec BFS/DFS<br>â€¢ Utiliser les mots-clÃ©s think/megathink |
| **Concepts ClÃ©s** | Chain-of-Thought, Tree-of-Thought, BFS, DFS, scoring |
| **Mots-ClÃ©s** | `ToT`, `CoT`, `thought`, `branch`, `prune`, `evaluate` |
| **Outils/Techniques** | TreeOfThought, Evaluator, Pruner |
| **Fichiers Code** | `src/agent/reasoning/tot-reasoning.ts` |
| **RÃ©fÃ©rences** | Tree-of-Thoughts (Yao et al., NeurIPS 2023) |
| **PrÃ©requis** | Ch.03 (Anatomie Agent) |
| **Chapitres LiÃ©s** | Ch.05 (MCTS), Ch.06 (Repair) |

---

> ğŸ“Œ **Ã€ Retenir**
>
> **ToT = CoT + exploration parallÃ¨le + Ã©valuation**. Au lieu de suivre un seul chemin de raisonnement, ToT explore plusieurs hypothÃ¨ses simultanÃ©ment et garde les plus prometteuses.

---

## ğŸ¯ 4.1 Le ProblÃ¨me du Raisonnement LinÃ©aire

### 4.1.1 ğŸ”— La Limite Fondamentale

Les LLMs gÃ©nÃ¨rent du texte **token par token**, chaque token dÃ©pendant des prÃ©cÃ©dents. C'est la gÃ©nÃ©ration autorÃ©gressive.

![GÃ©nÃ©ration AutorÃ©gressive](images/autoregressive_gen.svg)

Si le modÃ¨le s'engage sur une mauvaise piste au token 50, il doit continuer sur cette piste jusqu'Ã  la fin. **Pas de retour en arriÃ¨re possible.**

### 4.1.2 ğŸ® Exemple Concret : Le Game of 24

Le **Game of 24** est un benchmark classique : utiliser quatre nombres avec +, -, Ã—, Ã· pour obtenir 24.

![Tree-of-Thought vs Linear](images/tot_vs_cot.svg)

### 4.1.3 ğŸ§  Pourquoi Ã‡a Marche

ToT imite le raisonnement humain naturel :

| ğŸ§  Ce que fait l'humain | ğŸŒ³ Ce que fait ToT |
|:------------------------|:-------------------|
| "Et si j'essayais X ?" | GÃ©nÃ©rer N pensÃ©es candidates |
| "Cette piste a l'air prometteuse" | Scorer chaque pensÃ©e (0-1) |
| "Je continue sur celle-ci" | SÃ©lectionner les meilleures |
| "Non, mauvaise idÃ©e, revenons" | Ã‰laguer et backtracker |

> ğŸ’¡ **Insight clÃ©** : Les humains ne pensent pas en ligne droite. Ils explorent, Ã©valuent, abandonnent, recommencent. ToT donne cette capacitÃ© aux LLMs.

---

## ğŸ“ 4.2 L'Algorithme Tree-of-Thought

### 4.2.1 ğŸ—ï¸ Structure de DonnÃ©es

Chaque pensÃ©e est un **nÅ“ud** dans un arbre :

```typescript
interface ThoughtNode {
  id: string;
  content: string;           // Le contenu de cette pensÃ©e
  score: number;             // Ã‰valuation de la promesse (0-1)
  depth: number;             // Profondeur dans l'arbre
  parent: ThoughtNode | null;
  children: ThoughtNode[];
  state: 'pending' | 'expanded' | 'pruned' | 'solution';
  metadata: {
    generatedAt: Date;
    evaluatedBy: 'self' | 'vote' | 'execution';
    confidence: number;
  };
}

interface ThoughtTree {
  root: ThoughtNode;
  problem: string;
  maxDepth: number;
  branchingFactor: number;   // Combien d'enfants par nÅ“ud
  solutions: ThoughtNode[];  // Solutions trouvÃ©es
}
```

### 4.2.2 ğŸ”„ Les Quatre Phases

![Phases ToT](images/tot_phases.svg)

1.  **DÃ©composer** : Casser le problÃ¨me en Ã©tapes.
2.  **GÃ©nÃ©rer** : CrÃ©er plusieurs options pour la prochaine Ã©tape.
3.  **Ã‰valuer** : Juger chaque option.
4.  **SÃ©lectionner** : Garder les meilleures et recommencer.

### 4.2.3 ğŸŒ² Visualisation d'un Arbre

![Tree-of-Thought Example](images/tot_example_tree.svg)

---

## ğŸ§­ 4.3 Les StratÃ©gies de Recherche

Il existe plusieurs faÃ§ons de parcourir l'arbre. Le choix de la stratÃ©gie impacte fortement les rÃ©sultats.

### 4.3.1 ğŸ“Š Comparaison des StratÃ©gies

| ğŸ§­ StratÃ©gie | ğŸ“ Description | âœ… Avantages | âš ï¸ InconvÃ©nients |
|:-------------|:---------------|:-------------|:-----------------|
| **BFS** | Explorer tous les nÅ“uds d'un niveau avant le suivant | Ne rate pas de solution proche | CoÃ»teux en mÃ©moire et appels |
| **DFS** | Explorer une branche jusqu'au bout | Ã‰conome en mÃ©moire | Peut s'enliser dans une impasse |
| **Beam** | Garder les K meilleurs Ã  chaque niveau | Bon compromis | Peut Ã©laguer une bonne branche |

### 4.3.2 ğŸ“ Visualisation des StratÃ©gies

![StratÃ©gies de Recherche](images/search_strategies.svg)

### 4.3.5 ğŸ¯ Configuration RecommandÃ©e par TÃ¢che

| ğŸ¯ Type de TÃ¢che | ğŸ§­ StratÃ©gie | ğŸŒ¿ Branching | ğŸ“ Depth | ğŸ“Š Beam |
|:-----------------|:-------------|:------------:|:--------:|:-------:|
| Bug simple | BFS | 3 | 2 | 3 |
| Bug complexe | Beam | 4 | 4 | 3 |
| Refactoring | DFS | 2 | 6 | 2 |
| Architecture | Beam | 5 | 3 | 4 |
| Optimisation | Beam | 4 | 5 | 3 |

---

## âš–ï¸ 4.4 L'Ã‰valuation des PensÃ©es

L'Ã©valuation est **critique** â€” une mauvaise Ã©valuation mÃ¨ne Ã  de mauvaises dÃ©cisions d'Ã©lagage.

### 4.4.1 ğŸ“Š Trois MÃ©thodes d'Ã‰valuation

| ğŸ”§ MÃ©thode | ğŸ“ Description | âœ… Avantages | âš ï¸ InconvÃ©nients |
|:-----------|:---------------|:-------------|:-----------------|
| **Self** | Le LLM Ã©value ses propres pensÃ©es | Simple, un seul appel | Biais vers ses propres idÃ©es |
| **Vote** | Plusieurs Ã©valuations, puis moyenne | Plus robuste | Plus d'appels API |
| **Execution** | ExÃ©cuter le code et vÃ©rifier | Objectif, prÃ©cis | Seulement pour le code |

### ğŸ§ª Laboratoire : ImplÃ©menter une Auto-Ã©valuation

Voici comment implÃ©menter une Ã©valuation robuste avec un LLM :

```typescript
async function selfEvaluate(thought: ThoughtNode, problem: string): Promise<number> {
  const prompt = `
    ProblÃ¨me original : ${problem}

    PensÃ©e Ã  Ã©valuer : ${thought.content}

    Ã‰value cette pensÃ©e sur une Ã©chelle de 0 Ã  1 :
    - 0.0-0.2 : Hors sujet ou fausse
    - 0.3-0.4 : Peu prometteuse
    - 0.5-0.6 : Pertinente, mÃ©rite exploration
    - 0.7-0.8 : Prometteuse, probablement sur la bonne piste
    - 0.9-1.0 : Excellente, trÃ¨s probablement la solution

    RÃ©ponds UNIQUEMENT avec un nombre flottant (ex: 0.85).
  `;

  const response = await llm.complete(prompt);
  return parseFloat(response.trim());
}
```

---

## ğŸ’» 4.5 ImplÃ©mentation Grok-CLI

### 4.5.1 ğŸ“ Architecture du Module

```
src/agent/reasoning/
â”œâ”€â”€ index.ts                 # Point d'entrÃ©e, export
â”œâ”€â”€ tree-of-thought.ts       # ğŸŒ³ ImplÃ©mentation principale
â”œâ”€â”€ thought-generator.ts     # ğŸŒ± GÃ©nÃ©ration de pensÃ©es
â”œâ”€â”€ thought-evaluator.ts     # âš–ï¸ Ã‰valuation
â”œâ”€â”€ search-strategies.ts     # ğŸ§­ BFS, DFS, Beam
â”œâ”€â”€ types.ts                 # ğŸ“ Types TypeScript
â””â”€â”€ prompts/
    â”œâ”€â”€ decompose.ts         # Prompts de dÃ©composition
    â”œâ”€â”€ generate.ts          # Prompts de gÃ©nÃ©ration
    â””â”€â”€ evaluate.ts          # Prompts d'Ã©valuation
```

---

## ğŸ¬ 4.6 Cas Pratiques

### 4.6.1 ğŸ› Cas 1 : Debugging d'une Fonction

**ProblÃ¨me** : "calculateDiscount retourne parfois NaN"

L'arbre gÃ©nÃ©rÃ© (simplifiÃ©) :
1.  **HypothÃ¨se NaN** (Score 0.9)
    *   **Div par 0** (Score 0.85) -> **TrouvÃ© : `total / price`** -> **Fix : `if (price === 0)`**
    *   **Input undefined** (Score 0.7) -> Non reproduit

### 4.6.2 ğŸ—ï¸ Cas 2 : Refactoring d'Architecture

**ProblÃ¨me** : "Refactorer UserService"

L'arbre gÃ©nÃ©rÃ© :
1.  **StratÃ©gie Domaine** (Score 0.9) -> **Auth/Profile/Settings** -> **Plan Migration**
2.  **StratÃ©gie Technique** (Score 0.6) -> Controller/Service -> Ã‰laguÃ©

---

## âš™ï¸ 4.7 Optimisations et Bonnes Pratiques

### 4.7.1 ğŸ“Š RÃ©duire les Appels API

Au lieu d'Ã©valuer chaque pensÃ©e individuellement, demandez au LLM d'Ã©valuer une liste en une seule fois.

```typescript
// âœ… Ã‰valuation batch : 1 appel pour N pensÃ©es
async function batchEvaluate(thoughts: ThoughtNode[], problem: string): Promise<void> {
  const prompt = `... Ã‰value ces ${thoughts.length} pensÃ©es ...`;
  // ...
}
```

### 4.7.2 ğŸƒ Early Stopping

Si vous trouvez un score > 0.95, arrÃªtez tout et retournez la solution ! Pas besoin d'Ãªtre perfectionniste si le code marche.

---

## âš ï¸ 4.8 Limites et Risques du ToT

### ğŸš§ Limites Techniques

| Limite | Description | Impact |
|--------|-------------|--------|
| **CoÃ»t exponentiel** | B^D appels API (branching^depth) | Budget Ã©puisÃ© rapidement |
| **Ã‰valuation imparfaite** | LLM peut mal noter des bonnes pistes | Branches prometteuses abandonnÃ©es |
| **Profondeur limitÃ©e** | Au-delÃ  de 4-5 niveaux, qualitÃ© dÃ©cline | Solutions superficielles |
| **Pas de rollback** | Branches abandonnÃ©es = perdues | Peut manquer la bonne solution |
| **DÃ©pendance au prompt** | QualitÃ© trÃ¨s sensible au prompt d'Ã©valuation | RÃ©sultats inconsistants |

### âš¡ Risques OpÃ©rationnels

| Risque | ProbabilitÃ© | Impact | Mitigation |
|--------|:-----------:|:------:|------------|
| **Explosion des coÃ»ts** | Haute | Ã‰levÃ© | Beam Search + budget strict |
| **Paralysie d'analyse** | Moyenne | Moyen | Limite de profondeur, early stopping |
| **Faux positifs (bonnes notes, mauvaises solutions)** | Moyenne | Ã‰levÃ© | Validation par exÃ©cution |
| **Convergence prÃ©maturÃ©e** | Moyenne | Moyen | Exploration forcÃ©e (tempÃ©rature) |

### ğŸ“Š Quand NE PAS Utiliser ToT

| Situation | Raison | Alternative |
|-----------|--------|-------------|
| TÃ¢ches simples (< 3 Ã©tapes) | Overhead >> bÃ©nÃ©fice | Appel direct |
| Budget trÃ¨s limitÃ© | CoÃ»t exponentiel | CoT simple |
| Besoin de rapiditÃ© | Latence multipliÃ©e | Single-shot |
| Solution unique attendue | Exploration inutile | Prompt ciblÃ© |

**Estimations de coÃ»t :**

| Configuration | Appels max | CoÃ»t estimÃ© |
|:--------------|:----------:|:-----------:|
| Branching=3, Depth=4 | 3â´ = 81 | ~$0.40 |
| Branching=4, Depth=4 | 4â´ = 256 | ~$1.30 |

> ğŸ“Œ **Ã€ Retenir** : ToT est un **investissement** â€” utilisez-le uniquement quand la valeur du problÃ¨me justifie le coÃ»t. Pour un bug critique en production, 256 appels API valent le coup. Pour formatter un fichier JSON, c'est du gaspillage.

---

## ğŸ“ 4.9 Points ClÃ©s Ã  Retenir

*   **ToT** permet de sortir des impasses du raisonnement linÃ©aire.
*   **Beam Search** est souvent la meilleure stratÃ©gie pour le code (Ã©quilibre coÃ»t/qualitÃ©).
*   **L'Ã©valuation** est l'Ã©tape la plus difficile et la plus importante.

---

## ğŸ‹ï¸ Exercices

### Exercice 1 : Dessiner un Arbre de PensÃ©es (20 min)

Pour le problÃ¨me suivant, dessinez l'arbre ToT complet :

> "La fonction `parseDate` retourne `Invalid Date` pour certaines entrÃ©es"

1. Listez 4 hypothÃ¨ses initiales (nÅ“uds de niveau 1)
2. Attribuez un score (0-1) Ã  chaque hypothÃ¨se
3. DÃ©veloppez les 2 meilleures en sous-hypothÃ¨ses (niveau 2)
4. Identifiez quelle branche mÃ¨ne probablement Ã  la solution

### Exercice 2 : ImplÃ©menter une Ã‰valuation par Vote (30 min)

ImplÃ©mentez une fonction d'Ã©valuation par vote qui appelle le LLM 3 fois et retourne la moyenne :

```typescript
interface VoteEvaluationResult {
  scores: number[];      // Les 3 scores individuels
  average: number;       // Moyenne
  variance: number;      // Variance (indicateur de confiance)
  consensus: boolean;    // true si variance < 0.1
}

async function voteEvaluate(
  thought: ThoughtNode,
  problem: string,
  llm: LLMClient
): Promise<VoteEvaluationResult> {
  // Votre implÃ©mentation ici
}
```

Bonus : Ajoutez un mÃ©canisme de "tie-breaker" si la variance est trop Ã©levÃ©e.

### Exercice 3 : Choisir la Bonne StratÃ©gie (15 min)

Pour chaque scÃ©nario, indiquez la stratÃ©gie optimale (BFS, DFS, ou Beam) et justifiez :

1. Trouver rapidement UN fix pour un test qui Ã©choue
2. Explorer toutes les faÃ§ons de refactorer une classe
3. Debugging d'un problÃ¨me de performance avec budget limitÃ©
4. GÃ©nÃ©rer plusieurs alternatives d'architecture
5. RÃ©soudre un problÃ¨me mathÃ©matique avec une seule solution

### Exercice 4 : Calcul de CoÃ»t (15 min)

Calculez le nombre maximum d'appels API pour ces configurations :

| Configuration | Branching | Depth | Beam | Appels max ? |
|:--------------|:---------:|:-----:|:----:|:------------:|
| Config A | 3 | 3 | - | ? |
| Config B | 4 | 4 | 2 | ? |
| Config C | 5 | 5 | 3 | ? |

Formules :
- BFS/DFS : `B^D` oÃ¹ B=branching, D=depth
- Beam : `B Ã— K Ã— D` oÃ¹ K=beam width

### Exercice 5 : ImplÃ©mentation Early Stopping (20 min)

Modifiez l'algorithme Beam Search pour implÃ©menter un early stopping intelligent :

```typescript
interface EarlyStopConfig {
  minScore: number;           // Score minimum pour arrÃªter (ex: 0.95)
  minConfidence: number;      // Confiance minimum (ex: 0.8)
  maxConsecutiveDecline: number; // ArrÃªter si N niveaux sans amÃ©lioration
}

function shouldStop(
  currentBest: ThoughtNode,
  history: ThoughtNode[],    // Meilleurs nÅ“uds des niveaux prÃ©cÃ©dents
  config: EarlyStopConfig
): boolean {
  // Votre implÃ©mentation ici
}
```

Testez avec un cas oÃ¹ le score stagne Ã  0.7 pendant 3 niveaux.

---

| â¬…ï¸ PrÃ©cÃ©dent | ğŸ“– Sommaire | â¡ï¸ Suivant |
|:-------------|:-----------:|:-----------|
| [Anatomie d'un Agent](03-anatomie-agent.md) | [Index](README.md) | [Monte-Carlo Tree Search](05-mcts.md) |
